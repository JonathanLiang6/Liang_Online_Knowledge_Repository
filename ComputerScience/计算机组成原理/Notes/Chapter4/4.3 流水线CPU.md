### 4.3.1 流水线 CPU 概述
#### 4.3.1.1 流水线概述
**流水线**：
能使多条指令重叠执行+的实现技术
**非流水线** CPU： 
同一时刻每条指令独占整个数据通道 
每个时钟完成一条指令，但是时钟周期很长  
**流水线** CPU:
将一个过程拆分成 k 个阶段:同一时刻,每条指令只占 datapath 的一部分,多条指令分别占用 datapath 的不同部分
最长阶段决定时钟周期，即**时钟频率**
**RISC-V 流水线**：分为五个阶段，每个阶段完成一个步骤
IF: 从指令内存中读取指令 
ID: 指令的解码 & 读取寄存器的值 
EX: ALU 完成计算（ld/sd 计算地址） 
MEM: 访问数据内存（仅 ld/sd 指令） 
WB: 将结果写回寄存器
#### 4.3.1.2 性能问题
最长阶段决定时钟周期，关键路径：load 指令(会使用所有五个阶段：Instruction memory → register file → ALU → data memory → register file)
不同指令使用不同的时钟，在物理实现上是不可行的。但是，不同延时的指令共用时钟周期，是一个次优的方案。
那些快速的指令会浪费时间去等待。此时，CPU的某些阶段会空闲，因此要应用[[#4.3.1.1 流水线概述|流水线]]
#### 4.3.1.3 流水线 CPU 加速比
1. 当所有阶段是均衡的（每阶段的速度一致）情况下
$两条指令的间隔_{流水线}=\frac{两条指令的间隔_{非流水线}}{阶段的数目}$
2. 如果阶段是不平衡的，加速比会下降
同时，流水线面临额外的开销
加速比源于吞吐量的提升：单条指令的延时并未下降，通常情况下反而会上升
#### 4.3.1.4 ISA 设计对流水线影响
RISC-V  ISA 为流水线而设计：
所有指令都是 32 位宽：更容易在一个周期内完成[[4.1 单周期CPU数据通路#4.1.2.2 取指令|取指]]或[[4.1 单周期CPU数据通路#4.1.2.3 解码|解码]]
更少且更规整的指令格式：可以在同一个周期内完成解码和[[4.1 单周期CPU数据通路#4.1.2.4 读取寄存器|读取寄存器]]
专门的访存指令——load/store:可以在第 3 阶段计算地址，第 4 阶段访问内存
### 4.3.2 流水线冒险
#### 4.3.2.1 冒险简介
**冒险**：妨碍在下个周期连续开始下条指令的情形 
可以分为以下三种形式：**[[#4.3.2.2 结构冒险——物理资源竞争|结构冒险]]**、**[[#4.3.2.3 数据冒险——数据依赖|数据冒险]]**、**[[#4.2.3.4 控制冒险——控制依赖|控制冒险]]**
#### 4.3.2.2 结构冒险——物理资源竞争
资源使用的冲突：需要等待物理资源空闲	
`e.g 比如，前面的指令返过来使用后面的硬件资源：`
	如果 RISC-V 只有一个内存，Load/store 指令需要访问内存（第 1 条指令）后面指令需要停顿后，才能取指令（第 4 条指令） 因为内存不支持同时多个访问
  因此，流水线 CPU 的通路需要分开的**指令/数据内存**或者分开的**指令/数据缓存**
#### 4.3.2.3 数据冒险——数据依赖 
需要等待前面的指令完成读/写操作
`e.g 一条指令的数据依赖于前面计算的值`
```arm-asm
add x19, x0, x1
sub x2, x19, x3
```
**解决方法1**： 旁路/转发
前面的指令计算出值后，后面的指令直接使用
不用等待回写到寄存器，但需要数据通路上增加额外的连线，连线叫做旁路(或转发)forwarding ![[../../Picture/Pasted image 20241207153337.png]]
**旁路也不能避免停顿**：
后面指令需要值时，前面指令还没完成计算，只能停顿。旁路可能来不及。
**解决方法 2**：通过代码调度来避免停顿
通过重排代码，避免在 load 指令后面的指令立即 use![[../../Picture/Pasted image 20241207153624.png]]
#### 4.2.3.4 控制冒险——控制依赖 
需要等待前面指令的运算结果，才能决定后续执行哪条指令
**分支指令决定了控制流** 
下一条指令取决于分支结果：流水线取指令时，等不及前面分支指令的结果（前面分支指令可能仍在 ID 阶段）
在 RISC-V 流水线中，一种优化是在流水线的早期阶段比较寄存器并计算出分支的目标地址，增加硬件在 ID 阶段计算分支结果
**分支导致停顿**：
下一条指令的 IF 阶段必须停顿等待，直到分支结果计算完成![[../../Picture/Pasted image 20241207155654.png]]
通常在 MEM 阶段完成获得分支结果
#### 4.2.3.5 分支预测
- 对于长流水线 CPU 来说，很难在早期确定分支结果，会导致巨大的停顿代价。可以预测分支的结果，只有预测错误的时候，才停顿。
- 在 RISC-V 流水线中
	- 可以预测分支为：不跳转（not taken）。
	- 立即取指分支指令的下一条指令。
##### 循环语句的编译
- C 代码: `while (save[i] == k) i += 1;`
- `i` in `x22`, `k` in `x24`, `save` 数组的地址 in `x25`。
- 对应的 RISC-V 汇编指令:
 ```assembly
  Loop:
      slli x10, x22, 3
      add x10, x10, x25
      ld x9, 0(x10)
      bne x9, x24, Exit (预测不跳转?)
      addi x22, x22, 1
      beq x0, x0, Loop (预测跳转?)
  Exit:
      …
```
##### 更实际的分支预测器
- **静态分支预测**：基于典型的分支行为，比如循环和条件分支指令。
    - 后向分支：预测为跳转。
    - 前向分支：预测为不跳转。
- **动态分支预测**：用硬件测量实际的分支行为，即记录每个分支的近期是否跳转的历史，假设历史可以预测未来。
    - 如果预测错误，则：停顿，重新取新的目标指令，更新历史。
##### 流水线
总结
流水线通过提升指令吞吐量来提升性能：
通过并行执行多条指令，每条指令需要同样的延时。
流水线会被冒险妨碍，包括结构、数据、控制冒险。
指令集设计会影响流水线实现的复杂度。
### 4.3.3 数据通路与流水线控制
#### 4.3.3.1 数据通路介绍
![[../../Picture/Pasted image 20241208112921.png]]
**流水线寄存器**：各个阶段之间需要寄存器，用于存储每周期更新的状态信息
指令**逐级**经过流水线数据通路：**每周期经过一级** 
“单周期” 流水线图：
	展示单个周期内流水线通路的使用 
	突出展示单个周期内，资源的使用 
“多周期” 流水线图 
	展示一条指令在不同周期使用的资源 
	![[../../Picture/Pasted image 20241208160219.png]]
#### 4.3.3.2 流水线的控制
控制信号来自指令（与单周期 CPU 相同）
需要**逐级**向后传递
![[../../Picture/Pasted image 20241208171139.png]]
![[../../Picture/Pasted image 20241208171156.png]]
![[../../Picture/Pasted image 20241208171223.png]]

###  [[../../Contents/第四章 处理器|回到目录]]